HubSit Health Analytics ETL ğŸ¥ğŸ“Š

Este projeto consiste em um pipeline de Engenharia de Dados desenvolvido em Python para analisar e mitigar o absenteÃ­smo (No-Show) em clÃ­nicas mÃ©dicas. O projeto foi desenvolvido como parte de uma consultoria acadÃªmica para a startup de saÃºde HubSit.


ğŸ¯ Objetivo

Transformar dados brutos e desestruturados de agendamentos ambulatoriais em inteligÃªncia de negÃ³cios, permitindo:

Identificar o perfil de pacientes propensos ao No-Show.

Calcular a Receita Potencial vs. Realizada e o impacto financeiro das faltas.

Otimizar a gestÃ£o da agenda mÃ©dica atravÃ©s de indicadores de capacidade e ocupaÃ§Ã£o.

ğŸ› ï¸ Tecnologias Utilizadas

Linguagem: Python 3.10+

ManipulaÃ§Ã£o de Dados: Pandas, NumPy

VisualizaÃ§Ã£o: Power BI (alimentado pelos outputs deste script)

Conceitos: ETL (Extract, Transform, Load), Data Cleaning, Data Modeling.

âš™ï¸ Funcionalidades do Pipeline

O script etl_pipeline.py realiza as seguintes etapas:

IngestÃ£o: Leitura automatizada de arquivos CSV/TXT com tratamento de mÃºltiplos encodings (UTF-8/Latin1).

Limpeza (Data Cleaning):

NormalizaÃ§Ã£o de nomes de mÃ©dicos e pacientes.

ExclusÃ£o de agendas administrativas (Ex: Cirurgias, Testes) via blacklist.

Tratamento de valores nulos e inconsistÃªncias de datas.

Regras de NegÃ³cio:

ClassificaÃ§Ã£o de status: No-Show, Cancelamento Tardio (<24h) e Atendido.

DefiniÃ§Ã£o de Pacientes Novos vs. Recorrentes.

CriaÃ§Ã£o de Faixas EtÃ¡rias dinÃ¢micas.

ExportaÃ§Ã£o: GeraÃ§Ã£o de tabelas dimensÃ£o e fato otimizadas na pasta data/processed/ para consumo direto no Power BI.

ğŸš€ Como Executar

Clone este repositÃ³rio:

git clone [https://github.com/Brenezes/HubSit-Health-Analytics-ETL.git](https://github.com/Brenezes/HubSit-Health-Analytics-ETL.git)


Instale as dependÃªncias:

pip install -r requirements.txt


Coloque seus arquivos de dados na pasta data/raw/ (verifique os nomes esperados no script).

Execute o pipeline:

python src/etl_pipeline.py


Os arquivos processados aparecerÃ£o em data/processed/.

ğŸ“Š Estrutura dos Dados Gerados

O pipeline gera os seguintes arquivos para modelagem (Star Schema):

fato_agendamentos.csv: Base analÃ­tica completa.

financeiro.csv: Receita e ticket mÃ©dio por procedimento.

perfil_noshow.csv: Taxas de falta por sexo, idade e indicaÃ§Ã£o.

atravessamento.csv: Tempos de espera e pontualidade.

ğŸ‘¨â€ğŸ’» Autor

Breno Menezes
Data Engineer | Data Analytics
LinkedIn


### Resumo do Plano de AÃ§Ã£o:
1.  Crie a pasta do projeto no seu computador.
2.  Crie as subpastas `src`, `data`, `docs`.
3.  Mova seu cÃ³digo para `src` e renomeie.
4.  Crie o `requirements.txt` e o `README.md`.
5.  DÃª `git init`, `git add .`, `git commit -m "Initial commit"` e suba para o GitHub.

